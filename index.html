---
layout: landing
---
				<!-- Banner -->
					<section id="banner">
						<div class="inner">
							<h2>{{ site.title }}</h2>
							<p>{{ site.description | markdownify }}</p>
							<!-- <ul class="actions">
								<li><a href="#" class="button special">Activate</a></li>
							</ul> -->
						</div>
						<a href="#projects" class="more scrolly">View Projects</a>
					</section>

				<!-- One -->
					<!-- <section id="one" class="wrapper style1 special">
						<div class="inner">
							<header class="major">
								<h2>Arcu aliquet vel lobortis ata nisl<br />
								eget augue amet aliquet nisl cep donec</h2>
								<p>Aliquam ut ex ut augue consectetur interdum. Donec amet imperdiet eleifend<br />
								fringilla tincidunt. Nullam dui leo Aenean mi ligula, rhoncus ullamcorper.</p>
							</header>
							<ul class="icons major">
								<li><span class="icon fa-diamond major style1"><span class="label">Lorem</span></span></li>
								<li><span class="icon fa-heart-o major style2"><span class="label">Ipsum</span></span></li>
								<li><span class="icon fa-code major style3"><span class="label">Dolor</span></span></li>
							</ul>
						</div>
					</section> -->

				<!-- Two -->
				
                <section id="projects" class="wrapper alt style6">
					<section class="spotlight">
        				<div class="image"><img src="images/vla_cover.jpeg" alt="" /></div><div class="content">
							<h2><a href="vla_rohot.html">Vision-Language-Action Model Integration</a></h2>
							<p>I integrated  Vision-Language-Action (VLA) models with a UR5e robotic arm to enable natural language control of robotic manipulation tasks. The project involved deploying a complete perception and control pipeline on an NVIDIA Jetson Orin, implementing real-time motion execution in ROS + URScript, and achieving sub-200ms end-to-end latency from command input to motion initiation. Key challenges included debugging singularities, handling workspace edge cases, calibrating coordinate frames, and optimizing inference performance for autonomous manipulation.</p>
						</div>
    				</section>

                    <section class="spotlight">
                        <div class="image" ><img src="images/omni_cover.JPG" alt="" /></div><div class="content">
                            <h2><a href="boeing-project-II.html">The Complete Boeing Project</a></h2>
                                <p>A continuation from Part I below, this quarter brought forth a complete redesign of the Omni robot base. Instead of using the Arduino Mega microcontroller and Kangaroo motion controllers, we have switched over to the Tiva C Series microcontroller from National Instruments. Thus, the architecture of the base is exactly the same as the inverted delta robotic arm that will sit ontop of it - creating a more robust sytem. The goal of this quarter was to build and program three of these robots while making sure throughout the process that the calculated odometry was as accurate as possible. Finally, instead of controlling each robot individually, we were tasked to control them formation style - where the user controls the velocity of a 'pivot' point and the robots move relative to that point.
                            </p>
                        </div>
                    </section>
					<section class="spotlight">
						<div class="image" ><img src="images/Assembly.jpg" alt="" /></div><div class="content">
							<h2><a href="boeing-project-I.html">Boeing Project - Part I</a></h2>
								<p>Robots have revolutionized the way manufacturing is done in industry. A couple examples include the <a href="https://www.wsj.com/video/at-tesla-workers-team-up-with-robot-superheroes/F9732D42-BAC6-47AE-B226-87E945966ADF.html"target="_blank">'X-men'</a> robots working at Tesla and the <a href="https://www.youtube.com/watch?v=UtBa9yVZBJM"target="_blank">'KIVA'</a> robots zooming around Amazon's fulfillment centers. The aerospace sector is no different. In this project, originally inspired by Boeing, the goal is to design three robots to work together to take an airplane wing from a crane, transport it to the fuselage of the airplane, and reorient it so that it would be easy for workers to bolt it into place. Last year, a team of MSR students in conjunction with <a href="https://nxr.northwestern.edu/people/matthew-elwin"target="_blank">Matt Elwin</a> (the project lead and advisor) built a <a href="https://www.superdroidrobots.com/shop/item.aspx/programmable-mecanum-wheel-vectoring-robot-ig52-db/1788/"target="_blank">programmable mecanum wheel vectoring robot</a> from a kit bought at SuperDroid (shown on the left) with the idea to prove the concept on a smaller scale first. However, some issues regarding the mechanical structure, electrical design, safety measures, and hardware components were not solved. Finding solutions for these issues and updating the robot accordingly were the goals for this quarter.
								</p>
						</div>
					</section>
            <section class="spotlight">
              <div class="image" ><img src="images/sawyerGIF.gif" alt="" /></div><div class="content">
                <h2><a href="inverted_pen.html">Inverted Pendulum</a></h2>
                <p>Nobody can take a controls or dynamics course without encountering the classic inverted pendulum problem. Even if you're not an engineer, you have probably tried to balance a broomstick or dowel on the tip of your finger at some point or other, and might have even been able to keep it up for a minute or two! However, the question remains, how can one reliably balance a pendulum such that it never falls, and can respond to force disturbances? Well, with a robot of course! For my Winter Project, I programmed Sawyer, a robot by <a href="http://www.rethinkrobotics.com"target="_blank">Rethink Robotics</a> to do just that! Click <a href="https://drive.google.com/open?id=1FXJXsdRcDxJXS-Kua1aB4rFsKBY5Y83M"target="_blank">here</a> to see a demo and checkout my GitHub <a href="https://github.com/swiz23/inverted_pendulum"target="_blank">README</a> for more info.  </p>
              </div>
            </section>
            <section class="spotlight">
              <div class="image"><img src="images/mechatronics.JPG" alt="" /></div><div class="content">
                <h2><a href="mechatronics.html">DC Motor Control</a></h2>
                <p>A must have in many robotics projects, brushed DC motors are a cheap way to make robots 'come to life'. When combined with an encoder or gearhead, it is easy to track the motor's position and speed, and adjust the outputted torque respectively. In this project, I designed a controller to rotate a shaft based on various reference trajectories. Check out the video <a href="https://drive.google.com/open?id=1Xv8EI4bMiqLz7tWjW6sWyvQFIau30P0j"target="_blank">here</a> to see a demo.</p>
              </div>
            </section>
						<section class="spotlight">
							<div class="image"><img src="images/plinkoProject.gif" alt="" /></div><div class="content">
								<h2><a href="plinko.html">Plinko</a></h2>
								<p>Predicting the future might be difficult, but predicting if a Plinko disk will score you a jackpot? Not so much. With the help of Lagrangian Dynamics, it is possible to construct equations describing the motion of an object and simulate it. Then, by tweaking the initial conditions and forces acting on the object, you can alter the way it moves. This is especially helpful in robotics where visualization of how a robot might move in real life is key to its success.</p>
							</div>
						</section>
						<section class="spotlight">
							<div class="image"><img src="images/sniper_cover.png" alt="" /></div><div class="content">
								<h2><a href="finger_sniper.html">Finger Sniper</a></h2>
								<p>From license plate and optical character recognition to self driving cars, computer vision plays a large role in helping robots maneuver their surroundings. But it can also be used for fun and games! In this project, a player uses their finger to shoot a ball as many times as possible while it bounces within the borders of the image. If it is hit, the ball changes color and the player receives a point. Time is short though as the ball shrinks every time it hits a border, and once it gets too small the game is over! To play it yourself, click <a href="https://github.com/swiz23/computer_vision"target="_blank">here</a> and follow the instructions in the README.</p>
							</div>
						</section>
						<section class="spotlight">
							<div class="image"><img src="images/kuka_cover.png" alt="" /></div><div class="content">
								<h2><a href="kuka_youBot_control.html">KUKA youBot Control</a></h2>
								<p>A core part of robotics is the ability to manipulate robots effectively. One awesome example of this can be seen <a href="https://www.youtube.com/watch?v=bAdqazixuRY"target="_blank">here</a>, in a video by Nigel Stanford, where he makes KUKA robots play musical instruments! On a simpler level, my project uses concepts such as rigid-body motion, forward, velocity, and inverse kinematics, and feedback control to move a KUKA youBot's end effector along a desired path.</p>
							</div>
						</section>
						<section class="spotlight">
							<div class="image"><img src="images/ball_tracker.png" alt="" /></div><div class="content">
								<h2><a href="camera_ball_tracker.html">Camera Ball Tracker</a></h2>
								<p>Nowadays, it is possible for pan/tilt security cameras to be equipped with motion auto-tracking software such as the Hikvision camera shown <a href="https://www.youtube.com/watch?v=UBUpCO1dmVI&list=PLuVMXoPaIpeTt-YLC_h3enRj1VJuxxDbL&index=12"target="_blank">here</a>. This allows the recording of possibly suspicious events in detail using computer vision techniques. On a simpler level, this project uses color segmentation in the HSV space to isolate the red hue of the ball from the surrounding colors. The centroid of the red blob is then found in the camera frame. Finally, the pan/tilt servos of the camera are automatically adjusted to keep the centroid in the center of the frame. For more info, click <a href="https://github.com/swiz23/ball_tracker"target="_blank">here</a> to access the GitHub repo and check out the README.</p>
							</div>
						</section>
                        <section class="spotlight">
                            <div class="image"><img src="images/rrt_logo.png" alt="" style="width: 80%"/></div><div class="content">
                                <h2><a href="rrt.html">Path Planning With RRT</a></h2>
                                <p>An essential part to robot navigation, path planning makes is possible for a robot to move from one location to another while avoiding obstacles. In this project, the focus was on the Rapidly-Exploring Random Tree (RRT) algorithm. Simply put, this algorithm guarantees the rapid exploration of some vector space. As exploration is a crucial element of path planning, it is vital that it should take the least amount of time possible so that there is not much delay between when the robot is commanded to go to a specific position and it actually moving. To look at the source code and Runtime instructions, click <a href="https://github.com/swiz23/path_planning"target="_blank">here</a>.</p>
                            </div>
                        </section>
            <section class="spotlight">
              <div class="image"><img src="images/starbaxPic.jpg" alt="" /></div><div class="content">
                <h2><a href="starbax.html">Starbax</a></h2>
                <p>Need a cup of coffee but don't want to make it? Meet Baxter - a robot created by <a href="http://www.rethinkrobotics.com"target="_blank">Rethink Robotics</a> that's ready to serve you! Using computer vision feedback, augmented reality tags, and inverse kinematics, Baxter can make a mean cup of joe using a Keurig, K-cup, and cup. My contribution to this team project was to use image processing to locate and identify these items. Check out the video <a href="https://vimeo.com/246536038"target="_blank">here</a> for a demo and this <a href="https://github.com/Laurenhut/ME495-final-project"target="_blank">README</a> for more info.  </p>
              </div>
            </section>
					</section>

					<section id="about" class="wrapper style1 special">
											<div class="inner">
												<header class="major">
													<div class="row">
														<div class="6u 12u$(medium)">
															<h2>Interests</h2>
															<ul>
																<li>Autonomous Robots</li>
                                                                <li>VLA Models</li>
																<li>Robot Operating System</li>
																<li>Computer Vision</li>
																<li>Motion Planning</li>
																<li>Reinforcement Learning</li>
                                                                <li>Kinematics</li>
																<li>Controls</li>
																<li>3D Modeling</li>
																<li>Everything else that comes with a robot ðŸ˜„</li>
														
																
															</ul>
														</div>
														<div class="6u$ 12u$(medium)">
															<h2>About</h2>
																<p align="left">Thanks for stopping by! Iâ€™m Manas, a robotics engineer with a Masters degree in Robotics and Autonomous Systems for Boston University.
																	Iâ€™ve had the privilege of working on cool projects, from configuring various robotic platforms to implementing advanced path planning and motion control algorithms. My core interests include robotic perception, motion planning, and optimization techniques. Whether itâ€™s developing reinforcement learning models for obstacle avoidance or integrating sensors for precise object manipulation, I enjoy building autonomy for robots from the ground up.
																	
																	When Iâ€™m not immersed in robotics, youâ€™ll likely find me exploring national parks on a hike or stargazing in some of the worldâ€™s darkest and most serene locations.
																	</p>
																<p align="right"><b>-Manas</b></p>
														</div>
													</div>

													<hr />

												<p align="left"><b>Want to know more?</b> Check out my <a href=https://medium.com/@manasvini.srini target="blank">blog!

												</header>
												<ul class="icons major">
													<li><a href="https://www.linkedin.com/in/manasvini-srinivasan" target="blank" class="icon fa-linkedin-square fa-3x"><span class="label">LinkedIn</span></a></li>
													<li><a href="resume.pdf" target="blank" class="icon fa-file-pdf-o fa-3x"><span class="label">Resume</span></a></li>
													<li><a href="mailto:msrini@bu.edu" class="icon fa-envelope-o fa-3x"><span class="label">Email</span></a></li>
												</ul>
											</div>
										</section>


				<!-- Three -->
					<!-- <section id="three" class="wrapper style3 special">
						<div class="inner">
							<header class="major">
								<h2>Accumsan mus tortor nunc aliquet</h2>
								<p>Aliquam ut ex ut augue consectetur interdum. Donec amet imperdiet eleifend<br />
								fringilla tincidunt. Nullam dui leo Aenean mi ligula, rhoncus ullamcorper.</p>
							</header>
							<ul class="features">
								<li class="icon fa-paper-plane-o">
									<h3>Arcu accumsan</h3>
									<p>Augue consectetur sed interdum imperdiet et ipsum. Mauris lorem tincidunt nullam amet leo Aenean ligula consequat consequat.</p>
								</li>
								<li clashttps://medium.com/@manasvini.sriniAenean Primis</h3>
									<p>Augue consectetur sed interdum imperdiet et ipsum. Mauris lorem tincidunt nullam amet leo Aenean ligula consequat consequat.</p>
								</li>
								<li class="icon fa-flag-o">
									<h3>Tortor Ut</h3>
									<p>Augue consectetur sed interdum imperdiet et ipsum. Mauris lorem tincidunt nullam amet leo Aenean ligula consequat consequat.</p>
								</li>
							</ul>
						</div>
					</section> -->

				<!-- CTA -->
					<!-- <section id="cta" class="wrapper style4">
						<div class="inner">
							<header>
								<h2>Arcue ut vel commodo</h2>
								<p>Aliquam ut ex ut augue consectetur interdum endrerit imperdiet amet eleifend fringilla.</p>
							</header>
							<ul class="actions vertical">
								<li><a href="#" class="button fit special">Activate</a></li>
								<li><a href="#" class="button fit">Learn More</a></li>
							</ul>
						</div>
					</section> -->

					<!-- contact -->
		<section id="contact" class="wrapper style4">
			<div class="inner">
				<header>
					<h2>Contact</h2>
					<p>Send me a message, always excited to meet someone new ðŸ˜Š</p>
					<!-- <h4>Contact Form</h4> -->
					<form method="POST" action="https://formspree.io/solomonwiznitzer2018@u.northwestern.edu">
						<div class="row uniform">
							<div class="6u 12u$(xsmall)">
								<input type="text" name="name" id="name" value="" placeholder="Name" />
							</div>
							<div class="6u$ 12u$(xsmall)">
								<input type="email" name="email" id="email" value="" placeholder="Email Address" />
							</div>
							<div class="6u$ 12u$(small)">
								<input type="checkbox" id="ishuman" name="ishuman" unchecked>
								<label for="ishuman">Not a robot</label>
							</div>
							<div class="12u$">
								<textarea name="message" id="message" placeholder="Enter your message" rows="6"></textarea>
							</div>
							<div class="12u$">
								<ul class="actions">
									<li><input type="submit" value="Send Message" class="special" /></li>
									<li><input type="reset" value="Reset" /></li>
								</ul>
							</div>
						</div>
					</form>
				</header>
			</div>
		</section>
